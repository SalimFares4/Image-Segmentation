{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFEZgv4-DgiH",
        "outputId": "333f2289-6642-4b5c-912d-0861c9112a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCVlW0kCrGAb"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation-models-pytorch\n",
        "!pip install rasterio\n",
        "!pip install richdem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2R1a13NEq_cr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import pandas as pd  \n",
        "import richdem as rd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ixN8koNs0fz"
      },
      "outputs": [],
      "source": [
        "# Root Directory\n",
        "Image_Segmentation_Path = '/content/drive/My Drive/Image Segmentation/'\n",
        "\n",
        "# Inputs/Sources\n",
        "\n",
        "dataframes_path = Image_Segmentation_Path + \"DataFrames/\"\n",
        "\n",
        "# This is the entire dataset. We'll do it later.\n",
        "# dirs_pairs = dataframes_path + \"complete_dirs_pairs.csv\"\n",
        "# train_dirs_path = dataframes_path + 'complete_train_dirs.csv'\n",
        "# validate_dirs_path = dataframes_path + 'complete_validate_dirs.csv'\n",
        "# test_dirs_path = dataframes_path + 'complete_test_dris.csv'\n",
        "\n",
        "\n",
        "dirs_pairs = dataframes_path + \"origin_dirs_pairs.csv\"\n",
        "train_dirs_path = dataframes_path + 'origin_train_dirs.csv'\n",
        "validate_dirs_path = dataframes_path + 'origin_validate_dirs.csv'\n",
        "test_dirs_path = dataframes_path + 'origin_test_dris.csv'\n",
        "\n",
        "\n",
        "#dirs_pairs = dataframes_path + \"slope_dirs_pairs.csv\"\n",
        "#train_dirs_path = dataframes_path + 'slope_train_dirs.csv'\n",
        "#validate_dirs_path = dataframes_path + 'slope_validate_dirs.csv'\n",
        "#test_dirs_path = dataframes_path + 'slope_test_dris.csv'\n",
        "\n",
        "\n",
        "#dirs_pairs = dataframes_path + \"aspect_dirs_pairs.csv\"\n",
        "#train_dirs_path = dataframes_path + 'aspect_train_dirs.csv'\n",
        "#validate_dirs_path = dataframes_path + 'aspect_validate_dirs.csv'\n",
        "#test_dirs_path = dataframes_path + 'aspect_test_dris.csv'\n",
        "\n",
        "\n",
        "#dirs_pairs = dataframes_path + \"hillshade_dirs_pairs.csv\"\n",
        "#train_dirs_path = dataframes_path + 'hillshade_train_dirs.csv'\n",
        "#validate_dirs_path = dataframes_path + 'hillshade_validate_dirs.csv'\n",
        "#test_dirs_path = dataframes_path + 'hillshade_test_dris.csv'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUpSQ4kTx00i"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset as BaseDataset\n",
        "from torch import FloatTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8yEtXWHq7UW"
      },
      "outputs": [],
      "source": [
        "class Dataset(BaseDataset):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "      images_dir (str): path to images folder\n",
        "      masks_dir (str): path to segmentation masks folder\n",
        "      class_values (list): values of classes to extract from segmentation mask\n",
        "  \"\"\"\n",
        "    \n",
        "  CLASSES = ['non-mound', 'mound', 'invalid data']\n",
        "    \n",
        "  def __init__(\n",
        "          self, \n",
        "          dirs,\n",
        "          classes=None,\n",
        "          augmentation=None):\n",
        "    self.df = pd.read_csv(dirs)\n",
        "    self.ids = self.df['Index'].values.tolist()\n",
        "    \n",
        "    # convert str names to class values on masks\n",
        "    self.class_values = CLASSES = [0.5, 1, 0]\n",
        "      \n",
        "      \n",
        "    self.augmentation = augmentation\n",
        "    \n",
        "  def __getitem__(self, i):\n",
        "    # read data\n",
        "    with rasterio.open(self.df.at[i, 'Input']) as dem:\n",
        "      dem_array = dem.read(1)\n",
        "      \n",
        "    with rasterio.open(self.df.at[i, 'Target']) as mask:\n",
        "      mask_array = mask.read(1)\n",
        "\n",
        "    # apply augmentations\n",
        "    if self.augmentation:\n",
        "      sample = self.augmentation(image=dem_array, mask=mask_array)\n",
        "      dem_array, mask_array = sample['image'], sample['mask']\n",
        "        \n",
        "    dem_array = FloatTensor(np.expand_dims(dem_array,axis=(0)))\n",
        "    mask_array = FloatTensor(np.expand_dims(mask_array,axis=(0)))\n",
        "    \n",
        "    return dem_array, mask_array\n",
        "      \n",
        "  def __len__(self):\n",
        "    return len(self.ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhvwAtDbw1La"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset(dirs_pairs, classes=['mound'])\n",
        "dem_array, mask_array = dataset[1] # get some sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0uIRL8jXW8V",
        "outputId": "31d2b850-245d-4f89-ebb8-7216756e2923"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 201, 177])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "mask_array.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zigdKOLZMGHF"
      },
      "outputs": [],
      "source": [
        "import albumentations as albu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kLzCeN5Mcz3"
      },
      "outputs": [],
      "source": [
        "def get_training_augmentation():\n",
        "  train_transform = [albu.PadIfNeeded(min_height=320, min_width=320, always_apply=True, border_mode=0)]\n",
        "\n",
        "  return albu.Compose(train_transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVYkGDBaMufo"
      },
      "outputs": [],
      "source": [
        "def get_validation_augmentation():\n",
        "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
        "    test_transform = [\n",
        "        albu.PadIfNeeded(384, 480)\n",
        "    ]\n",
        "    return albu.Compose(test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32FET1wgx8wU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import segmentation_models_pytorch as smp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nl_KYATi0sXY"
      },
      "outputs": [],
      "source": [
        "# ENCODER = 'se_resnext50_32x4d'\n",
        "# ENCODER_WEIGHTS = 'imagenet'\n",
        "# ACTIVATION = 'softmax2d' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
        "# CLASSES = [0.5, 1, 0]\n",
        "# # create segmentation model with pretrained encoder\n",
        "# model = smp.FPN(\n",
        "#     encoder_name=ENCODER, \n",
        "#     encoder_weights=ENCODER_WEIGHTS, \n",
        "#     classes=len(CLASSES), \n",
        "#     in_channels=1,\n",
        "#     activation=ACTIVATION,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4sVkN3xDb4G"
      },
      "outputs": [],
      "source": [
        "CLASSES = [0.5, 1, 0]\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
        "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
        "    classes=len(CLASSES),\n",
        "    in_channels=1,\n",
        "    activation='softmax2d'                  # model output channels (number of classes in your dataset)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ9u7sMb1G2w"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(train_dirs_path,\n",
        "                        augmentation=get_training_augmentation(),                         \n",
        "                        classes=CLASSES)\n",
        "\n",
        "\n",
        "valid_dataset = Dataset(validate_dirs_path,\n",
        "                        augmentation=get_validation_augmentation(),                         \n",
        "                        classes=CLASSES)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StnjhtYvVY0X",
        "outputId": "20ff81cc-60c9-474b-a329-5123f1d7ee33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 320, 320])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "dem, mask = train_dataset[100]\n",
        "dem.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCaJdE7o-kh7",
        "outputId": "78cacb2c-882a-4822-e133-918df217bd59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1636"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpq3oZ0mV7ul",
        "outputId": "3432d83c-b7c0-4709-e53b-0e7c4120ff3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5794)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "torch.max(dem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obVtGQas4F5X"
      },
      "outputs": [],
      "source": [
        "# Dice/F1 score - https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
        "# IoU/Jaccard score - https://en.wikipedia.org/wiki/Jaccard_index\n",
        "\n",
        "loss = smp.utils.losses.DiceLoss()\n",
        "metrics = [\n",
        "    smp.utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "\n",
        "optimizer = torch.optim.Adam([ \n",
        "    dict(params=model.parameters(), lr=0.0001),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31icQrNk4OOh"
      },
      "outputs": [],
      "source": [
        "# create epoch runners \n",
        "# it is a simple loop of iterating over dataloader`s samples\n",
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    optimizer=optimizer,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybZQBycD4SSu",
        "outputId": "dee8a304-d0d6-4146-a4b5-4a1cd51f647a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "train: 100%|██████████| 205/205 [35:10<00:00, 10.30s/it, dice_loss - 0.7479, iou_score - 0.1492]\n",
            "valid: 100%|██████████| 546/546 [06:31<00:00,  1.39it/s, dice_loss - 0.4652, iou_score - 0.2862]\n",
            "Model saved!\n",
            "\n",
            "Epoch: 1\n",
            "train: 100%|██████████| 205/205 [34:19<00:00, 10.04s/it, dice_loss - 0.7479, iou_score - 0.1496]\n",
            "valid: 100%|██████████| 546/546 [06:28<00:00,  1.41it/s, dice_loss - 0.4652, iou_score - 0.2856]\n",
            "\n",
            "Epoch: 2\n",
            "train:  47%|████▋     | 96/205 [16:04<18:35, 10.23s/it, dice_loss - 0.7481, iou_score - 0.1482]"
          ]
        }
      ],
      "source": [
        "# train model for 40 epochs\n",
        "\n",
        "max_score = 0\n",
        "\n",
        "for i in range(0, 40):\n",
        "    \n",
        "    print('\\nEpoch: {}'.format(i))\n",
        "    train_logs = train_epoch.run(train_loader)\n",
        "    valid_logs = valid_epoch.run(valid_loader)\n",
        "    \n",
        "    # do something (save model, change lr, etc.)\n",
        "    if max_score < valid_logs['iou_score']:\n",
        "        max_score = valid_logs['iou_score']\n",
        "        torch.save(model, './best_model.pth')\n",
        "        print('Model saved!')\n",
        "        \n",
        "    if i == 25:\n",
        "        optimizer.param_groups[0]['lr'] = 1e-5\n",
        "        print('Decrease decoder learning rate to 1e-5!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1GnvojI8hjC"
      },
      "outputs": [],
      "source": [
        "# load best saved checkpoint\n",
        "best_model = torch.load('./best_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUvXWCxq8k9t"
      },
      "outputs": [],
      "source": [
        "# create test dataset\n",
        "test_dataset = Dataset(test_dirs_path,\n",
        "                       augmentation=get_validation_augmentation(), \n",
        "                       preprocessing=get_preprocessing(preprocessing_fn),\n",
        "                       classes=CLASSES)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YdlbUxh8m99"
      },
      "outputs": [],
      "source": [
        "# evaluate model on test set\n",
        "test_epoch = smp.utils.train.ValidEpoch(\n",
        "    model=best_model,\n",
        "    loss=loss,\n",
        "    metrics=metrics)\n",
        "\n",
        "logs = test_epoch.run(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dr45XiCr8wGN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# for i in range(5):\n",
        "#     n = np.random.choice(len(test_dataset))\n",
        "    \n",
        "#     image_vis = test_dataset[n][0].astype('uint8')\n",
        "#     image, gt_mask = test_dataset[n]\n",
        "    \n",
        "    \n",
        "#     x_tensor = torch.from_numpy(image).unsqueeze(0)\n",
        "#     pr_mask = best_model.predict(x_tensor)\n",
        "#     pr_mask = (pr_mask.cpu().numpy().round())\n",
        "        \n",
        "#     visualize(\n",
        "#         image=image_vis, \n",
        "#         ground_truth_mask=gt_mask, \n",
        "#         predicted_mask=pr_mask\n",
        "#     )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Segmentation Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}